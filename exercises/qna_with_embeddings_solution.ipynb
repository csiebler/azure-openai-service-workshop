{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure OpenAI Service - Q&A with semantic answering tutorial\n",
    "\n",
    "In this tutorial, you'll build a simple Q&A system, that can give semantic answers to questions. Three sample documents from the Azure documentation are provided. Fill out the missing pieces in the source source to get everything working (indicated by `#FIXME`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import tiktoken\n",
    "import openai\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "from openai.embeddings_utils import cosine_similarity\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Configure OpenAI API\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version = \"2022-12-01\"\n",
    "openai.api_base = os.getenv('OPENAI_API_BASE')\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Define embedding model and encoding\n",
    "EMBEDDING_MODEL = 'text-embedding-ada-002'\n",
    "EMBEDDING_ENCODING = 'cl100k_base'\n",
    "EMBEDDING_CHUNK_SIZE = 8000\n",
    "COMPLETION_MODEL = 'text-davinci-003'\n",
    "\n",
    "# initialize tiktoken for encoding text\n",
    "encoding = tiktoken.get_encoding(EMBEDDING_ENCODING)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's read the documents in `samples/*.json`, which are our sample documents. The `content` section is the interesting piece of information for this tutorial:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"content\": \"\\n# What is Azure OpenAI?\\n\\nThe ...\",\n",
    "  \"product_name\": \"cognitive-services\",\n",
    "  \"title\": \"Azure Cognitive Services\",\n",
    "  \"description\": \"Apply advanced language models to variety of use cases with the Azure OpenAI service\",\n",
    "  \"topic\": \"overview\",\n",
    "  \"date\": \"11/07/2022\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3 documents\n",
      "Content:  # What is conversational language understanding? Conversational language unders... \n",
      "---> Tokens: 1341\n",
      "\n",
      "Content:  # What is Azure OpenAI? The Azure OpenAI service provides REST API access to Op... \n",
      "---> Tokens: 1891\n",
      "\n",
      "Content:  # What is Azure Cognitive Services Translator? Translator Service is a cloud-ba... \n",
      "---> Tokens: 739\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# list all files in the samples directory\n",
    "samples_dir = os.path.join(os.getcwd(), \"samples\")\n",
    "sample_files = os.listdir(samples_dir)\n",
    "\n",
    "# read content field from each file and append it to documents, and remove and newlines (better for embeddings later)\n",
    "documents = []\n",
    "for file in sample_files:\n",
    "    with open(os.path.join(samples_dir, file), \"r\") as f:\n",
    "        content = json.load(f)[\"content\"]\n",
    "        content = content.replace(\"\\n\", \" \")\n",
    "        content = content.replace(\"  \", \" \")\n",
    "        documents.append(content)\n",
    "\n",
    "# print some stats about the documents\n",
    "print(f\"Loaded {len(documents)} documents\")\n",
    "for doc in documents:\n",
    "    num_tokens = len(encoding.encode(doc))\n",
    "    print(f\"Content: {doc[:80]}... \\n---> Tokens: {num_tokens}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all documents loaded, we can embed them using our embedding model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1536\n",
      "1536\n",
      "1536\n"
     ]
    }
   ],
   "source": [
    "# Create embeddings for all docs\n",
    "embeddings = [openai.Embedding.create(input=doc, engine=EMBEDDING_MODEL)[\"data\"][0][\"embedding\"] for doc in documents]\n",
    "\n",
    "# print some stats about the embeddings\n",
    "for e in embeddings:\n",
    "    print(len(e))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our embeddings, we can try to ask some questions and see if it retrieves the correct document. You can try the following questions:\n",
    "\n",
    "* what is azure openai service?\n",
    "* can translator be fine tuned?\n",
    "* what is the difference between luis and clu?\n",
    "* what is form recognizer? (should yield no result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity to overview_clu.json is 0.649006202284026\n",
      "Similarity to overview_openai.json is 0.6491360198281905\n",
      "Similarity to overview_translator.json is 0.6335527344682663\n",
      "Matching document is overview_openai.json\n"
     ]
    }
   ],
   "source": [
    "# create embedding for question\n",
    "question = \"how is the weather today?\"\n",
    "qe = openai.Embedding.create(input=question, engine=EMBEDDING_MODEL)[\"data\"][0][\"embedding\"]\n",
    "\n",
    "# calculate cosine similarity between question and each document\n",
    "similaries = [cosine_similarity(qe, e) for e in embeddings]\n",
    "\n",
    "# Get the matching document, in this case we just use argmax of similarities\n",
    "max_i = np.argmax(similaries)\n",
    "\n",
    "# print some stats about the similarities\n",
    "for i, s in enumerate(similaries):\n",
    "    print(f\"Similarity to {sample_files[i]} is {s}\")\n",
    "print(f\"Matching document is {sample_files[max_i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question was: how is the weather today?\n",
      "Retrieved answer was:  I couldn't find the answer.\n"
     ]
    }
   ],
   "source": [
    "# Generate a prompt that we use for completion, in this case we put the matched document and the question in the prompt\n",
    "prompt = f\"\"\"\"\n",
    "Content:\n",
    "{documents[max_i]}\n",
    "Please answer the question below using only the content from above. If you don't know the answer or can't find it, say \"I couldn't find the answer\".\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "\n",
    "# get response from completion model\n",
    "response = openai.Completion.create(\n",
    "    engine=COMPLETION_MODEL,\n",
    "    prompt=prompt,\n",
    "    temperature=0.7,\n",
    "    max_tokens=500,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    "    stop=None\n",
    ")\n",
    "answer = response['choices'][0]['text']\n",
    "\n",
    "# print the question and answer\n",
    "print(f\"Question was: {question}\\nRetrieved answer was: {answer}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, that worked. Now we should have a simple understanding how Q&A can work using OpenAI embeddings and completions. Next step would be:\n",
    "\n",
    "* Chunking of longer documents (you might run into token limits for embeddings and the answering prompt)\n",
    "* Usage of a vector database (pinecone, redis, etc.) to scale the search part to a larger amount of documents\n",
    "* Evaluation of the top k results, instead of just the best matching document\n",
    "* ...and a few more!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai-qna-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c4ee1bbf3137c7ea9420c4fd488a55642063e5739fe2a7286130d9ba47405b69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
